# ğŸ§  TalentScout â€” AI Hiring Assistant Chatbot

### ğŸ‘©â€ğŸ’» Internship Project â€” AI/ML Intern Assignment  
**Developer:** Sornambal Palanisamy  
**Platform:** Google Colab (Gradio-based UI)  
**Tech Stack:** Python â€¢ Gradio â€¢ OpenAI API (GPT-4/3.5) â€¢ SQLite â€¢ Cryptography  

---

## ğŸš€ Project Overview

**TalentScout Hiring Assistant** is an AI-powered chatbot designed to automate the **initial screening process** for candidates applying to technology roles.  

It interacts conversationally to:
- Collect essential candidate information  
- Understand their tech stack  
- Generate tailored **technical interview questions**  
- Store responses securely for recruiter review  

This project demonstrates the use of **LLMs (Large Language Models)** for intelligent dialogue handling and **prompt engineering** for dynamic content generation.

---

## ğŸ¯ Key Functionalities

| Feature | Description |
|----------|--------------|
| ğŸ¤ Greeting & Introduction | Bot welcomes the user and explains its purpose |
| ğŸ§ Candidate Information Collection | Gathers name, email, phone, experience, position, and location |
| ğŸ§  Tech Stack Detection | Accepts technologies like Python, Django, React, etc. |
| âš™ï¸ Dynamic Question Generation | Uses LLMs to create 3â€“5 relevant technical questions per tech |
| ğŸ—‚ï¸ Context Handling | Maintains chat flow and avoids repetition |
| ğŸ§© Fallback Responses | Provides meaningful prompts for invalid inputs |
| ğŸ” Secure Data Handling | Stores encrypted candidate details in SQLite |
| âœ… Graceful Conversation End | Thanks the user and outlines next steps upon exit |
| ğŸ’¾ Simulated Data Storage | Stores responses locally in `talentscout.db` |
| ğŸ“¦ Optional | Can be deployed on Streamlit Cloud / Hugging Face Spaces |

---

## ğŸ§° Tech Stack

| Component | Technology Used |
|------------|----------------|
| Programming Language | Python 3 |
| Frontend / UI | Gradio |
| Backend | OpenAI GPT-4 (or fallback generator) |
| Database | SQLite (Simulated data storage) |
| Security | `cryptography.Fernet` for encryption |
| Environment | Google Colab |

---

## ğŸ§© Prompt Design

### ğŸ›ï¸ System Prompt
```
You are TalentScout's AI Hiring Assistant. 
Collect candidate information (name, contact, experience, desired role, location, tech stack) and generate 3â€“5 technical questions for each declared technology. 
Maintain a polite, professional tone and end the chat gracefully when the user types 'end', 'bye', or 'exit'.
```

### ğŸ¯ Technical Question Generation Prompt
```
Generate 3â€“5 concise technical interview questions for the technology: {tech}.
Candidate experience: {years} years.
Position applied: {position}.
Output format: numbered list of short questions (no answers).
```

### ğŸ’¬ Example Conversation
```
ğŸ‘‹ Hi, Iâ€™m TalentScout Hiring Assistant! Please tell me your full name.
> Hi I am Sornambal
Nice to meet you, Sornambal! Please provide your email address.
> email: sornambal@gmail.com
Email saved. Please provide your phone number.
> phone: +919876543210
Great! How many years of experience do you have?
> 3
Got it â€” 3 years of experience noted. What position are you applying for?
> Python Developer
Understood. Where are you currently located?
> Chennai
Thanks! Whatâ€™s your tech stack?
> tech: Python, Django
âœ… Tech stack saved: Python, Django.
Iâ€™ve generated questions. Type 'show' to view them.
```

---

## ğŸ’¾ Data Handling & Privacy

- Candidate data is **simulated** and stored locally in `talentscout.db`.  
- Sensitive fields (Name, Email, Phone) are **encrypted** using `Fernet` before saving.  
- Tech stack and generated questions are stored as JSON.  
- No real candidate data or external API logs are collected.

---

## ğŸ§© Installation & Usage

### ğŸ§  Requirements
- Python 3.10+
- Google Colab or local Jupyter environment
- OpenAI API key (optional â€” fallback generator works offline)

### ğŸ“¦ Install Dependencies
```bash
!pip install gradio openai cryptography
```

### ğŸ”‘ Set API Key (optional)
```python
import os
os.environ["OPENAI_API_KEY"] = "sk-xxxxxxxxxxxxxxxx"
```

### â–¶ï¸ Run the App
```python
!python app.py
```
Or in Colab:
```python
app.launch(share=True)
```

### ğŸ’¬ Usage Steps
1. Run all notebook cells in order.  
2. Enter your OpenAI key (optional).  
3. Chat through the Gradio interface.  
4. Provide candidate info and tech stack.  
5. Type `show` to view generated questions.  
6. Type `end` to finish â€” the bot saves your responses securely.

---

## ğŸ§  Technical Details

| Module | Description |
|---------|--------------|
| `validate_email()` / `validate_phone()` | Input validation helpers |
| `generate_questions()` | Calls GPT-4 or fallback generator |
| `handle()` | Manages conversation flow |
| `reset()` | Resets chatbot session |
| `save_candidate()` | Encrypts and saves user data to SQLite |
| `fallback_questions()` | Default question generator without API |

---

## ğŸ“Š System Design Overview

```
+------------------------+
|  Gradio Chat UI        |
|  (Frontend)            |
+-----------+------------+
            |
            v
+------------------------+
|  handle() Logic        |
|  (State Management)    |
+-----------+------------+
            |
            v
+------------------------+
|  LLM / Fallback        |
|  (generate_questions)  |
+-----------+------------+
            |
            v
+------------------------+
|  SQLite + Encryption   |
|  (Data Storage)        |
+------------------------+
```

---

## ğŸ’¬ Example Generated Output

**Tech Stack:** Python, Django  
**Generated Questions:**
```
Python:
1. Explain Python decorators.
2. What is the difference between a list and a tuple?
3. How does Python manage memory?

Django:
1. What are Django middleware and how are they used?
2. Explain Django ORM and query optimization.
3. What is the purpose of migrations in Django?
```

---

## ğŸ§© Challenges & Solutions

| Challenge | Solution |
|------------|-----------|
| Maintaining chat context | Used session dictionary to track fields |
| Handling invalid input | Implemented regex + fallback prompts |
| API failure or missing key | Added fallback static generator |
| PII storage security | Used `Fernet` encryption for sensitive data |
| Smooth exit flow | Added end keywords + polite summary |

---

## ğŸ§  Optional Enhancements (Bonus)

- **Sentiment Analysis:** Detect candidate tone during chat  
- **Multilingual Support:** Translate user messages using `langdetect`  
- **Cloud Deployment:** Streamlit Cloud / Hugging Face Spaces  
- **Recruiter Dashboard:** View saved candidate info & questions  

---

## ğŸ¥ Demo Instructions (for Loom / Submission)

1. Start your Colab notebook.  
2. Record with Loom:  
   - Greeting â†’ Info Collection â†’ Tech Stack â†’ â€œshowâ€ Questions â†’ â€œendâ€ â†’ Save.  
3. Keep video under 2 minutes.  
4. Include video link in your submission portal.

---

## ğŸ§¾ Submission Checklist

| Deliverable | Description | Status |
|--------------|-------------|---------|
| âœ… Source Code | Complete chatbot in Colab | âœ… |
| âœ… Working Demo | Gradio chat tested successfully | âœ… |
| âœ… README.md | Complete documentation | âœ… |
| âœ… Secure Storage | SQLite + Encryption | âœ… |
| âœ… Optional Demo Video | Loom / Gradio link | âœ… |

---

## ğŸ“œ References

- [Streamlit Docs](https://docs.streamlit.io/)  
- [Gradio Documentation](https://gradio.app/docs/)  
- [OpenAI API Reference](https://platform.openai.com/docs/)  
- [Prompt Engineering Guide](https://www.promptingguide.ai/)  
- [GDPR Privacy Principles](https://gdpr.eu/)

---

## ğŸ Conclusion

This project successfully demonstrates how **LLMs** can automate **technical candidate screening** while maintaining data privacy and conversational flow.  
It aligns with the **AI/ML Intern Assignment** objectives â€” showcasing prompt design, context handling, and secure AI-powered automation.
